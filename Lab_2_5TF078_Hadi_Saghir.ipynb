{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgCiqSrMA7EE1bV6sfxdYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hadi-Saghir/Deep-Learning-Notebooks/blob/main/Lab_2_5TF078_Hadi_Saghir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lab 2: Transfer Learning**\n",
        "## Author: Hadi Saghir (hasa0182)\n",
        "\n",
        "This lab will demonstrate knowledge and ability to apply transfer learning (TA) in convolution neural netweorks (CNN).\n",
        "\n",
        "This document will contain 4 parts:\n",
        "- Prelude\n",
        "- Applying the VGG16 model and expirmenting with the last layers.\n",
        "- Fine tuning our model\n",
        "- Applying the Xception model\n",
        "\n",
        "\n",
        "**OBS! i got permission from Tomas to update my document only regarding feedback from lab 1**"
      ],
      "metadata": {
        "id": "CePbUVqktIw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prelude\n",
        "\n",
        "##Intialize python enviroment anc check for the GPU"
      ],
      "metadata": {
        "id": "bDkRFT81yj4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ITUuNZbnDDEr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-wDgL9xsGvu",
        "outputId": "5cb9a8ac-b15a-4a19-cf0f-d2b3318a823d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n",
            "Keras version: 2.9.0\n",
            "GPU 0: Tesla T4 (UUID: GPU-5d0243d2-6e21-d2c5-386d-962dd8e52db4)\n"
          ]
        }
      ],
      "source": [
        "# Import needed libraries\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "# from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras.utils  import to_categorical\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "\n",
        "#from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16;\n",
        "from keras.applications import Xception;\n",
        "\n",
        "print('Keras version:',tf.keras.__version__)\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from   sklearn.model_selection import train_test_split\n",
        "\n",
        "# Matlab plotting\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test for GPU and determine what GPU we have\n",
        "import sys\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "     print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "     IN_COLAB = 'google.colab' in sys.modules\n",
        "     if IN_COLAB:\n",
        "         print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "else:\n",
        "     !nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define general attributes and functions\n",
        "\n",
        "Defininf parameters, functions and classes that will be used by the all three parts. My generator will allow use to stream and transfer simultaneously while decrease he need for space as images will be streamed and processed in batches."
      ],
      "metadata": {
        "id": "L0mnph3gfCgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.saved_model.model_utils.mode_keys import EstimatorModeKeys\n",
        "\n",
        "# Define the parameters\n",
        "IMG_WIDTH = 64\n",
        "IMG_HEIGHT = 64\n",
        "IMG_DEPTH = 3 #the img_transform changes 1 to 3 automatically when greyscale.to.rgb is called\n",
        "input_shape = (IMG_WIDTH, IMG_HEIGHT, IMG_DEPTH)\n",
        "\n",
        "BATCH_SIZE = 16 # batch size for generator (must be divisible by batch_size)\n",
        "batch_size = 32 # batch size for training\n",
        "\n",
        "# Define an in-stream transform (gray2color, resize)\n",
        "def img_transform(images):\n",
        " images = tf.image.grayscale_to_rgb(tf.convert_to_tensor(images))\n",
        " images = tf.image.resize_with_pad(images, IMG_WIDTH, IMG_HEIGHT, antialias=False)\n",
        " return images\n",
        "\n",
        "# Define a Sequence generator\n",
        "class Mygenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, x_set, y_set, batch_size):\n",
        "    self.x, self.y = x_set, y_set\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    end = min(self.x.shape[0], (idx + 1)*batch_size)\n",
        "    batch_x = self.x[idx * self.batch_size : end]\n",
        "    batch_y = self.y[idx * self.batch_size : end]\n",
        "    # transform the images to fit the model constraints\n",
        "    x=img_transform(batch_x)\n",
        "    print(\"batch_y = \", batch_y.shape)\n",
        "    y=to_categorical(batch_y)\n",
        "    print(\"y = \", y.shape)\n",
        "    return np.array(x), np.array(y)\n"
      ],
      "metadata": {
        "id": "ClCcaTyDy0Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "o_BJ5MzOzBX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Fashion-MNIST training and test data from Keras database (https://keras.io/datasets/)\n",
        "dir_path_train = \"/kaggle/input/fast-food-classification-dataset/Fast Food Classification V2/Train\"\n",
        "dir_path_test = \"/kaggle/input/fast-food-classification-dataset/Fast Food Classification V2/Test\"\n",
        "dir_path_valid = \"/kaggle/input/fast-food-classification-dataset/Fast Food Classification V2/Valid\"\n",
        "(train_images0, train_labels0), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Define labels\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Split the training set into a training and a validation set (20% is validation)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images0, train_labels0, test_size=0.20)\n",
        "\n",
        "# Add an \"empty\" color dimension for our data sets\n",
        "train_images = np.expand_dims(train_images, -1)\n",
        "val_images = np.expand_dims(val_images, -1)\n",
        "test_images = np.expand_dims(test_images, -1)\n",
        "\n",
        "# Generate data streams of from data sets (OBS! block of code for resize of entire dataset)\n",
        "train_gen = Mygenerator(train_images, train_labels, batch_size = BATCH_SIZE )\n",
        "val_gen = Mygenerator(train_images, train_labels, batch_size = BATCH_SIZE )\n",
        "test_gen = Mygenerator(test_images, test_labels, batch_size = BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "WjPT3QD0zIGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71966e36-1c1d-4d36-bfdd-6f1aec42771e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resize entire dataset"
      ],
      "metadata": {
        "id": "AH53vUNggc98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make labels categorical\n",
        "train_labels_cat = to_categorical(train_labels)\n",
        "test_labels_cat = to_categorical(test_labels)\n",
        "val_labels_cat = to_categorical(val_labels)\n",
        "\n",
        "#resize dataset (attrbutes definied in the definition block found above)\n",
        "train_images = img_transform(train_images)\n",
        "val_images = img_transform(val_images)\n",
        "test_images = img_transform(test_images)"
      ],
      "metadata": {
        "id": "TsYr9yIrggho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### print info on the dataset"
      ],
      "metadata": {
        "id": "SCtkX7WOgSRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print info of the dataset\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(val_images.shape)\n",
        "\n",
        "classes = np.unique(train_labels)\n",
        "num_classes = len(classes)\n",
        "print('Training labels:', np.unique(train_labels), \"; That is,\", num_classes,\"classes.\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oWTVdYJgPu3",
        "outputId": "f051616f-1c5e-4691-dc64-efc9c9244579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 64, 64, 3)\n",
            "(10000, 64, 64, 3)\n",
            "(12000, 64, 64, 3)\n",
            "Training labels: [0 1 2 3 4 5 6 7 8 9] ; That is, 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the VGG16 model and expirmenting with the last layers."
      ],
      "metadata": {
        "id": "YDIb3NUSFP7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the model"
      ],
      "metadata": {
        "id": "IOGADI_RhKWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define out vgg_model\n",
        "vgg_model = VGG16(    include_top=False,\n",
        "                      weights=\"imagenet\",\n",
        "                      input_tensor= None,\n",
        "                      input_shape = input_shape,\n",
        "                      pooling=None,\n",
        "                      classes=10,\n",
        "                      classifier_activation=\"softmax\",\n",
        "                 )\n",
        "\n",
        "# Creating dictionary that maps layer names to the layers\n",
        "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
        "\n",
        "# Getting output tensor of the last VGG layer that we want to include\n",
        "x = layer_dict['block3_pool'].output\n",
        "\n",
        "# Stacking a new simple convolutional network on top of it\n",
        "x = keras.layers.BatchNormalization(axis=-1)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
        "x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "# Creating new model. Please note that this is NOT a Sequential() model.\n",
        "from keras.models import Model\n",
        "model = Model(vgg_model.input, x)\n",
        "\n",
        "# Adjust the trainable layers are not trainable\n",
        "for layer in model.layers[0:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "87rC64oI6Ytb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30171a06-aec5-41cb-adb6-208b9d108fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8, 8, 256)        1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               8389120   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,130,762\n",
            "Trainable params: 8,394,762\n",
            "Non-trainable params: 1,736,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "  optimizer='Adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['categorical_accuracy']\n",
        ")\n",
        "\n",
        "# Generate data streams from data sets\n",
        "epochs = 100\n",
        "\n",
        "es=tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=3, mode='auto', min_delta=0, restore_best_weights = True)\n",
        "rl = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=2, min_lr=0)\n",
        "callbacks =[es,rl]\n",
        "\n",
        "\"\"\"\n",
        "# Training using streams\n",
        "history = model.fit(train_gen,\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch=train_images.shape[0]\n",
        "                    shuffle=True,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_gen,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# Evaluate\n",
        "score = model.evaluate(test_gen)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\"\"\"\n",
        "\n",
        "# Training using existing data\n",
        "history = model.fit(train_images, to_categorical(train_labels),\n",
        "                    epochs=epochs,\n",
        "                    shuffle=True,\n",
        "                    verbose=1,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=[val_images, to_categorical(val_labels)],\n",
        "                    callbacks=callbacks\n",
        "                    )\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(test_images, to_categorical(test_labels))\n",
        "\n",
        "\n",
        "# Print evalutation\n",
        "print('Test accuracy: %.3f' % test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEvG4X92Fiep",
        "outputId": "f1716a49-048f-4433-aaf6-71596a0eb583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 18s 11ms/step - loss: 0.8588 - categorical_accuracy: 0.8554 - val_loss: 0.3955 - val_categorical_accuracy: 0.8670 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2765 - categorical_accuracy: 0.9001 - val_loss: 0.2597 - val_categorical_accuracy: 0.9044 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2330 - categorical_accuracy: 0.9165 - val_loss: 0.2431 - val_categorical_accuracy: 0.9126 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2093 - categorical_accuracy: 0.9246 - val_loss: 0.2217 - val_categorical_accuracy: 0.9233 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1782 - categorical_accuracy: 0.9370 - val_loss: 0.2577 - val_categorical_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1498/1500 [============================>.] - ETA: 0s - loss: 0.1578 - categorical_accuracy: 0.9434\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1578 - categorical_accuracy: 0.9434 - val_loss: 0.2278 - val_categorical_accuracy: 0.9264 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0824 - categorical_accuracy: 0.9703 - val_loss: 0.1970 - val_categorical_accuracy: 0.9357 - lr: 2.0000e-04\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0585 - categorical_accuracy: 0.9792 - val_loss: 0.2070 - val_categorical_accuracy: 0.9392 - lr: 2.0000e-04\n",
            "Epoch 9/100\n",
            "1499/1500 [============================>.] - ETA: 0s - loss: 0.0431 - categorical_accuracy: 0.9848\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0431 - categorical_accuracy: 0.9848 - val_loss: 0.2254 - val_categorical_accuracy: 0.9377 - lr: 2.0000e-04\n",
            "Epoch 10/100\n",
            "1496/1500 [============================>.] - ETA: 0s - loss: 0.0234 - categorical_accuracy: 0.9937Restoring model weights from the end of the best epoch: 7.\n",
            "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0233 - categorical_accuracy: 0.9937 - val_loss: 0.2249 - val_categorical_accuracy: 0.9388 - lr: 4.0000e-05\n",
            "Epoch 10: early stopping\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.2218 - categorical_accuracy: 0.9315\n",
            "Test accuracy: 0.932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore the training progress\n",
        "Show the training progress, by plotting the training and validation accuracy and loss"
      ],
      "metadata": {
        "id": "A6aLVA1ecqZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochrange = range(1, callbacks[0].stopped_epoch + 2) # change to the epoch it stopped at when adding the early stopping method\n",
        "train_acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochrange, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy (modell 1)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
        "plt.plot(epochrange, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss (modell 1)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "zN0uaHLmcpuG",
        "outputId": "b6538008-fa47-4eaa-88f3-25ed314e5693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model on the test data.\n"
      ],
      "metadata": {
        "id": "drjiKLnkc2Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model.\n",
        "test_loss, test_acc = model.evaluate(test_images,to_categorical(test_labels))\n",
        "print('Test accuracy: %.3f' % test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zj21AQfc804",
        "outputId": "709ef3f1-5a2b-4ca8-cdbd-fc39b3ed83a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1799 - categorical_accuracy: 0.9413\n",
            "Test accuracy: 0.941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BSAsgwzLAJZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "\n",
        "### No trainble layers\n",
        "I didn't know i set all layers trainble = false. The result was stagnation after the first epoch at accruacy below 0.1. It was nice to see how that i still got some accuracy, but i am not sure if it is because of the pre-trained model.\n",
        "\n",
        "### Add trainble layers (VGG16 model is untrainble)\n",
        "After sitting for hours to figure why i was getting appalling bad results, i set the last layers to true. Mt total parameters were 11 million but 0 trainable.\n",
        "\n",
        "model:\n",
        "\n",
        "x = keras.layers.BatchNormalization(axis=-1)(x)  \n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
        "x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "The result jumped to 89.9%. One interesting trend i noted when i was trying to fine tune my additional layers was that my val_acc was 94% while the test_acc seemed low in comparison: 3-4% lower.\n",
        "\n",
        "### Scaling the image even further\n",
        "Applying the same model above, I scaled the image to (64,4). The test accuracy increased to 91.6%, but the val_accuracy was much higher still, so i guess it is over generalizing.\n",
        "\n",
        "### Decreasing the patience on the EarlyStopping\n",
        "I noticed that my (EarlyStopping) callbacks[0].patience = 10. Which is probably the reason for such early overfitting. I decreased the patience to 5 and instead of finishing on epoch 11, it finished on epoch 7. The result was 4 less epochs and a test_acc = 93%\n",
        "\n",
        "### Further tweaks\n",
        "I tried fiddling with the the image scale equal to (128,128) and (32,32), batch size equal to 28 or 128, and patience equal to 3 or 5, but they result was all relatively the same test_accuracy: 0.921. There wasn't much of a difference between the different tuning that are worth noting, and they all were on average 1% worse than my 93% attained earlier.\n",
        "\n",
        "### Further analysis\n",
        "Interesting tests for further analysis is to train blocks between untrained blocks -- test if that is even possible and its result."
      ],
      "metadata": {
        "id": "x0C6ngDQeqkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning our model"
      ],
      "metadata": {
        "id": "du7wtW2KALKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define out vgg_model\n",
        "vgg_model = VGG16(    include_top=False,\n",
        "                      weights=\"imagenet\",\n",
        "                      input_tensor= None,\n",
        "                      input_shape = input_shape,\n",
        "                      pooling=None,\n",
        "                      classes=10,\n",
        "                      classifier_activation=\"softmax\",\n",
        "                 )\n",
        "\n",
        "# Creating dictionary that maps layer names to the layers\n",
        "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
        "\n",
        "# Getting output tensor of the last VGG layer that we want to include\n",
        "x = layer_dict['block4_pool'].output\n",
        "\n",
        "# Stacking a new simple convolutional network on top of it\n",
        "x = keras.layers.BatchNormalization(axis=-1)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
        "x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "# Creating new model. Please note that this is NOT a Sequential() model.\n",
        "from keras.models import Model\n",
        "model = Model(vgg_model.input, x)\n",
        "\n",
        "# Adjust the trainable layers are not trainable\n",
        "for layer in model.layers[0:10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jDvaCCBCAFnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ef6fa7-5430-4826-be57-32c336345e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 512)               4194816   \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,837,258\n",
            "Trainable params: 10,100,746\n",
            "Non-trainable params: 1,736,512\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "\n",
        "I was able to attain a 94.1% accuracy!\n",
        "\n",
        "**The model i was using was the same for all of the different experiments**\n",
        "\n",
        "* x = keras.layers.BatchNormalization(axis=-1)(x)  \n",
        "* x = Flatten()(x)\n",
        "* x = Dense(512, activation='relu')(x)\n",
        "* x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
        "* x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "I will be fine-tuning the model by benchmarking the best amount of blocks to set to untrainable from pre-trained VGG16 model.\n",
        "\n",
        "### Block3_pool (10 million params, 8 million trainable)\n",
        "\n",
        "I started with block3_pool, which was the best fit for my previous attempt, but the result were underwhelming: capping at 92.6% accuracy in comparison to 92.7% to 93% with fewer parameter.\n",
        "\n",
        "attempt 1: I tried untrainble={block1} and the rest trainble, and the model was quicking overfitting at the best_epoch = 3. test_acc = 0.981.\n",
        "\n",
        "attempt 2: I tried untrainble={block1, block2} and the rest trainble, and the model was much more robust (train_acc and val_acc had a strong corelation) and only starting overfitting at the best_epoch = 9. test_acc = 0.926\n",
        "\n",
        "### Block4_pool (11,837k params)\n",
        "\n",
        "I started decided to increase to amount of blocks to 4, as i noticed more untrainable pre trained layers led often to better result, so in order to have 3 blocks of untrainble pre-trained layers to further build on to fine tune my model.\n",
        "\n",
        "attempt 3: I tried untrainble={block1, block2, block3} and trainble={block4}, and the model was very robust (train_acc and val_acc were spot on) and only starting overfitting at the best_epoch = 7. test_acc = 0.941! I still cannot figure out the anomalous outlier at epoch 2: insansely low val_acc and high  val_loss. I left the graph and accuracy evalutaton as is, but the compilation i changed to test other models. (10,100k trainable params)\n",
        "\n",
        "attempt 4: I tried untrainble={block1, block2} and trainble={block3, block4}, and the model was fluctuating (train_acc and val_acc were spot on) and starting overfitting fast with best_epoch = 5. test_acc = 0.899.\n",
        "\n",
        "### Block5_pool\n",
        "\n",
        "I tested 5 block to see if the trend, more blocks = higher accuracy, continues. However, this wasn't the case. test_acc was at best 90.3%.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "block4_pool attempt 3 was the sweet spot between underfittg and overfitting.\n"
      ],
      "metadata": {
        "id": "HzcCnE2hjeBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the Xception model"
      ],
      "metadata": {
        "id": "bmJhr3q52t0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the parameters\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_DEPTH = 3 #the img_transform changes 1 to 3 automatically when greyscale.to.rgb is called\n",
        "input_shape = (IMG_WIDTH, IMG_HEIGHT, IMG_DEPTH)\n",
        "\n",
        "# Define out vgg_model\n",
        "xception_model = Xception(    include_top=False,\n",
        "                      weights=\"imagenet\",\n",
        "                      input_tensor= None,\n",
        "                      input_shape = input_shape,\n",
        "                      pooling=None,\n",
        "                      classes=10,\n",
        "                      classifier_activation=\"softmax\",\n",
        "                 )\n",
        "\n",
        "# Creating dictionary that maps layer names to the layers\n",
        "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
        "\n",
        "# Getting output tensor of the last VGG layer that we want to include\n",
        "x = layer_dict['block4_pool'].output\n",
        "\n",
        "# Stacking a new simple convolutional network on top of it\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n",
        "x = Dense(units=num_classes, activation='softmax')(x)\n",
        "\n",
        "# Creating new model. Please note that this is NOT a Sequential() model.\n",
        "from keras.models import Model\n",
        "model = Model(vgg_model.input, x)\n",
        "\n",
        "# Adjust the trainable layers are not trainable\n",
        "for layer in model.layers[0:-14]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlH4qExO2ru9",
        "outputId": "60c06049-be87-4205-b49d-17f75488565c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 63, 63, 32)   864         ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " block1_conv1_bn (BatchNormaliz  (None, 63, 63, 32)  128         ['block1_conv1[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv1_act (Activation)  (None, 63, 63, 32)   0           ['block1_conv1_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 61, 61, 64)   18432       ['block1_conv1_act[0][0]']       \n",
            "                                                                                                  \n",
            " block1_conv2_bn (BatchNormaliz  (None, 61, 61, 64)  256         ['block1_conv2[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv2_act (Activation)  (None, 61, 61, 64)   0           ['block1_conv2_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block2_sepconv1 (SeparableConv  (None, 61, 61, 128)  8768       ['block1_conv2_act[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv1_bn (BatchNorma  (None, 61, 61, 128)  512        ['block2_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2_sepconv2_act (Activatio  (None, 61, 61, 128)  0          ['block2_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block2_sepconv2 (SeparableConv  (None, 61, 61, 128)  17536      ['block2_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv2_bn (BatchNorma  (None, 61, 61, 128)  512        ['block2_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 31, 31, 128)  8192        ['block1_conv2_act[0][0]']       \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 31, 31, 128)  0           ['block2_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 31, 31, 128)  512        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_156 (Add)                  (None, 31, 31, 128)  0           ['block2_pool[0][0]',            \n",
            "                                                                  'batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " block3_sepconv1_act (Activatio  (None, 31, 31, 128)  0          ['add_156[0][0]']                \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv1 (SeparableConv  (None, 31, 31, 256)  33920      ['block3_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv1_bn (BatchNorma  (None, 31, 31, 256)  1024       ['block3_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3_sepconv2_act (Activatio  (None, 31, 31, 256)  0          ['block3_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv2 (SeparableConv  (None, 31, 31, 256)  67840      ['block3_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv2_bn (BatchNorma  (None, 31, 31, 256)  1024       ['block3_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 16, 16, 256)  32768       ['add_156[0][0]']                \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 16, 16, 256)  0           ['block3_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_157 (Add)                  (None, 16, 16, 256)  0           ['block3_pool[0][0]',            \n",
            "                                                                  'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " block4_sepconv1_act (Activatio  (None, 16, 16, 256)  0          ['add_157[0][0]']                \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv1 (SeparableConv  (None, 16, 16, 728)  188672     ['block4_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv1_bn (BatchNorma  (None, 16, 16, 728)  2912       ['block4_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4_sepconv2_act (Activatio  (None, 16, 16, 728)  0          ['block4_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv2 (SeparableConv  (None, 16, 16, 728)  536536     ['block4_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv2_bn (BatchNorma  (None, 16, 16, 728)  2912       ['block4_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 8, 8, 728)    0           ['block4_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 46592)        0           ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 512)          23855616    ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 512)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 10)           5130        ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,785,090\n",
            "Trainable params: 24,589,378\n",
            "Non-trainable params: 195,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "\n",
        "### Including the whole model\n",
        "\n",
        "The result were much worse (0.857), parameters were 3 times higher (30 million compared to 10 million), and resizing of images to (71,71,3). The RAM and GPU consumption was high.\n",
        "\n",
        "I will approach fine-tuning the model by benchmarking the best amount of blocks to set to untrainable from pre-trained VGG16 model, as done above.\n",
        "\n",
        "\n",
        "### Block10/8/6_sepconv3_bn with untrainable layers [0:-5/-11]\n",
        "\n",
        "I tried benchmarking the different layers to add to analyze a trend. The less blocks i included, the better, as generalization was a problem. Xception does use a lot of regulization to reduce overtraining, thinking of all the activiations, batch normalization and pooling, yet this was not enough. I couldn't get a good fitting model. the results varried from 0.883 to 0.922 (block5_sepconv3_bn with [0:-14] layers untrainable)\n",
        "\n",
        "### Block4_pool and lower.\n",
        "\n",
        "This part of the model, the beginning, is really similar to the VGG16 model. So i tried my best to find a tuning better while including the addition blocks, however, restricting the layers to Block4_pool with [0:-14] seem to dwarf previous results.\n",
        "\n",
        "For further analysis, fine_tune the trainable layers while using Block4_pool,\n",
        "\n",
        "### Overall thoughts\n",
        "\n",
        "I feel like the Xception has potential to rival VGG16, but considering how small our images is, i need to scale up the picture even more to utilize all the layers the Xception is meant to provide. this becomes a question of resource as VGG16 preforms most probably slightly worse. Is the extra training worth."
      ],
      "metadata": {
        "id": "GGVuhViTFEja"
      }
    }
  ]
}